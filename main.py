#!/usr/bin/env python3
"""GitHub Trending æ¯æ—¥æ¨é€ - ä¸»å…¥å£"""

import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from src.scraper import scrape_trending
from src.analyzer import analyze_repos
from src.generator import generate_markdown, save_report
from src.history import (
    RankingEntry, save_ranking_history, load_yesterday_rankings,
    calculate_rank_changes, format_rank_change
)
from src.dashboard import generate_dashboard_html, save_dashboard
from src.ai_summary import batch_generate_summaries
from src.rss import generate_rss, save_rss


def main():
    """ä¸»å‡½æ•°"""
    print('ğŸš€ å¼€å§‹è·å– GitHub Trending æ•°æ®...')

    # 1. çˆ¬å– Trending æ•°æ®
    try:
        repos = scrape_trending()
        print(f'âœ… æˆåŠŸè·å– {len(repos)} ä¸ªçƒ­é—¨é¡¹ç›®')
    except Exception as e:
        print(f'âŒ çˆ¬å–å¤±è´¥: {e}')
        sys.exit(1)

    if not repos:
        print('âš ï¸ æœªè·å–åˆ°ä»»ä½•é¡¹ç›®ï¼Œé€€å‡º')
        sys.exit(0)

    # 2. åˆ†æé¡¹ç›®
    print('ğŸ“Š æ­£åœ¨åˆ†æé¡¹ç›®...')
    analyses = analyze_repos(repos, fetch_details=False)
    print(f'âœ… åˆ†æå®Œæˆï¼Œæœ€é«˜è¯„åˆ†: {analyses[0].score}/10')

    today = datetime.now()
    base_dir = Path(__file__).parent / 'archives'

    # 3. åˆ›å»ºæ’åæ¡ç›®
    print('ğŸ“ˆ æ­£åœ¨è®¡ç®—æ’åå˜åŒ–...')
    current_entries = []
    for i, analysis in enumerate(analyses, 1):
        current_entries.append(RankingEntry(
            name=analysis.repo.name,
            rank=i,
            stars=analysis.repo.stars,
            stars_today=analysis.repo.stars_today,
            language=analysis.repo.language,
            description=analysis.repo.description
        ))

    # 4. åŠ è½½æ˜¨å¤©æ•°æ®å¹¶è®¡ç®—å˜åŒ–
    yesterday_entries = load_yesterday_rankings(str(base_dir), today)
    rank_changes = calculate_rank_changes(current_entries, yesterday_entries)

    # ç»Ÿè®¡æ–°ä¸Šæ¦œé¡¹ç›®
    new_count = sum(1 for c in rank_changes if c.is_new)
    if yesterday_entries:
        print(f'âœ… å¯¹æ¯”æ˜¨æ—¥æ•°æ®å®Œæˆ: {new_count} ä¸ªæ–°ä¸Šæ¦œé¡¹ç›®')
    else:
        print('â„¹ï¸ æœªæ‰¾åˆ°æ˜¨æ—¥æ•°æ®ï¼Œæ‰€æœ‰é¡¹ç›®æ ‡è®°ä¸ºæ–°ä¸Šæ¦œ')

    # 5. ä¿å­˜ä»Šæ—¥æ’åå†å²
    history_path = save_ranking_history(current_entries, str(base_dir), today)
    print(f'âœ… æ’åæ•°æ®å·²ä¿å­˜: {history_path}')

    # 6. ç”Ÿæˆ AI æ™ºèƒ½æ€»ç»“ (ä¸º Top 10 é¡¹ç›®ç”Ÿæˆ)
    print('ğŸ¤– æ­£åœ¨ç”Ÿæˆ AI æ™ºèƒ½æ€»ç»“...')
    repos_for_ai = [
        {
            'name': a.repo.name,
            'description': a.repo.description,
            'language': a.repo.language,
            'stars': a.repo.stars,
            'stars_today': a.repo.stars_today,
            'topics': a.topics
        }
        for a in analyses[:10]
    ]
    ai_summaries = batch_generate_summaries(repos_for_ai, max_count=10)
    print(f'âœ… AI æ€»ç»“ç”Ÿæˆå®Œæˆ: {len(ai_summaries)} ä¸ªé¡¹ç›®')

    # 7. ç”Ÿæˆ Markdown æŠ¥å‘Š (å¸¦æ’åå˜åŒ–)
    print('ğŸ“ æ­£åœ¨ç”Ÿæˆ Markdown æŠ¥å‘Š...')
    markdown_content = generate_markdown_with_changes(analyses, rank_changes, today)
    md_path = save_report(markdown_content, base_dir=str(base_dir), date=today)
    print(f'âœ… Markdown æŠ¥å‘Šå·²ä¿å­˜: {md_path}')

    # 8. ç”Ÿæˆ HTML ä»ªè¡¨æ¿ (ä¸­æ–‡ç‰ˆ)
    print('ğŸ¨ æ­£åœ¨ç”Ÿæˆ HTML ä»ªè¡¨æ¿...')
    html_content_zh = generate_dashboard_html(analyses, rank_changes, today, lang='zh', ai_summaries=ai_summaries)
    html_path_zh = save_dashboard(html_content_zh, str(base_dir), today, lang='zh')
    print(f'âœ… ä¸­æ–‡ç‰ˆä»ªè¡¨æ¿å·²ä¿å­˜: {html_path_zh}')

    # 9. ç”Ÿæˆ HTML ä»ªè¡¨æ¿ (è‹±æ–‡ç‰ˆ)
    html_content_en = generate_dashboard_html(analyses, rank_changes, today, lang='en', ai_summaries=ai_summaries)
    html_path_en = save_dashboard(html_content_en, str(base_dir), today, lang='en')
    print(f'âœ… è‹±æ–‡ç‰ˆä»ªè¡¨æ¿å·²ä¿å­˜: {html_path_en}')

    # 10. ç”Ÿæˆ RSS Feed
    print('ğŸ“¡ æ­£åœ¨ç”Ÿæˆ RSS Feed...')
    rss_content = generate_rss(analyses, today)
    rss_path = save_rss(rss_content, str(base_dir))
    print(f'âœ… RSS Feed å·²ä¿å­˜: {rss_path}')

    # 11. è¾“å‡ºæ‘˜è¦
    print('\n' + '=' * 50)
    print(f'ğŸ“… æ—¥æœŸ: {today.strftime("%Y-%m-%d")}')
    print(f'ğŸ“Š æ”¶å½•é¡¹ç›®: {len(repos)} ä¸ª')
    print(f'ğŸ†• æ–°ä¸Šæ¦œ: {new_count} ä¸ª')
    print('\nğŸ† Top 5 æ¨è:')
    for i, analysis in enumerate(analyses[:5], 1):
        change = next((c for c in rank_changes if c.name == analysis.repo.name), None)
        change_str = format_rank_change(change) if change else ''
        print(f'  {i}. {analysis.repo.name} (â­ {analysis.score}/10) {change_str}')
    print('=' * 50)

    return 0


def generate_markdown_with_changes(analyses, rank_changes, date):
    """ç”Ÿæˆå¸¦æ’åå˜åŒ–çš„ Markdown æŠ¥å‘Š"""
    from src.generator import format_stars, score_to_stars, get_target_audience

    date_str = date.strftime('%Y-%m-%d')

    # åˆ›å»º name -> RankChange æ˜ å°„
    change_map = {c.name: c for c in rank_changes}

    # æŒ‰è¯„åˆ†æ’åº
    sorted_analyses = sorted(analyses, key=lambda x: x.score, reverse=True)

    # ç»Ÿè®¡è¯­è¨€åˆ†å¸ƒ
    lang_count = {}
    for a in analyses:
        lang = a.repo.language or 'Other'
        lang_count[lang] = lang_count.get(lang, 0) + 1

    top_langs = sorted(lang_count.items(), key=lambda x: x[1], reverse=True)[:5]
    lang_summary = ' | '.join(f'{lang}: {count}' for lang, count in top_langs)

    # ç»Ÿè®¡æ–°ä¸Šæ¦œ
    new_count = sum(1 for c in rank_changes if c.is_new)

    lines = [
        f'# GitHub Trending æ¯æ—¥ç²¾é€‰ ({date_str})',
        '',
        f'> ğŸ”¥ ä»Šæ—¥å…±æ”¶å½• **{len(analyses)}** ä¸ªçƒ­é—¨é¡¹ç›® | ğŸ†• æ–°ä¸Šæ¦œ **{new_count}** ä¸ª',
        f'>',
        f'> ğŸ“Š è¯­è¨€åˆ†å¸ƒ: {lang_summary}',
        '',
        '---',
        '',
    ]

    # æ–°ä¸Šæ¦œé¡¹ç›® Banner
    new_projects = [(a, change_map.get(a.repo.name)) for a in sorted_analyses
                    if change_map.get(a.repo.name) and change_map.get(a.repo.name).is_new]

    if new_projects:
        lines.extend([
            '## ğŸ†• ä»Šæ—¥æ–°ä¸Šæ¦œ',
            '',
        ])
        for analysis, change in new_projects[:5]:
            repo = analysis.repo
            desc = repo.description[:60] + '...' if len(repo.description) > 60 else repo.description
            lines.append(f'- **[{repo.name}]({repo.url})** - {desc} â­ {format_stars(repo.stars)} (+{repo.stars_today})')
        lines.extend(['', '---', ''])

    # Top 3 æ¨è
    lines.extend([
        '## ğŸ† ä»Šæ—¥é‡ç‚¹æ¨è',
        '',
    ])

    medals = ['ğŸ¥‡', 'ğŸ¥ˆ', 'ğŸ¥‰']
    for i, analysis in enumerate(sorted_analyses[:3]):
        repo = analysis.repo
        change = change_map.get(repo.name)
        change_str = format_rank_change(change) if change else ''

        # æ ¼å¼åŒ–è¯­è¨€
        if analysis.language_stats:
            lang_parts = [f'{lang} {pct:.0f}%' for lang, pct in list(analysis.language_stats.items())[:3]]
            lang_display = ', '.join(lang_parts)
        elif repo.language:
            lang_display = f'{repo.language} 100%'
        else:
            lang_display = 'æœªçŸ¥'

        star_display = score_to_stars(analysis.score)
        audience = get_target_audience(analysis)

        lines.extend([
            f'### {medals[i]} [{repo.name}]({repo.url})',
            f'> {analysis.readme_summary}' if analysis.readme_summary else '',
            '',
            '| æŒ‡æ ‡ | æ•°å€¼ |',
            '|------|------|',
            f'| â­ Star | {format_stars(repo.stars)} |',
            f'| ğŸ“ˆ ä»Šæ—¥æ–°å¢ | +{repo.stars_today} |',
            f'| ğŸ“Š æ’åå˜åŒ– | {change_str} |',
            f'| ğŸ”§ ä¸»è¦è¯­è¨€ | {lang_display} |',
            f'| ğŸ“Š æ¨èæŒ‡æ•° | {star_display} ({analysis.score}/10) |',
            '',
            f'**æ ¸å¿ƒåŠŸèƒ½**: {analysis.readme_summary[:100]}' if analysis.readme_summary else '',
            f'**æŠ€æœ¯æ ˆ**: {", ".join(analysis.tech_stack) if analysis.tech_stack else lang_display}',
            f'**é€‚åˆäººç¾¤**: {audience}',
            '',
            '---',
            '',
        ])

    # å®Œæ•´åˆ—è¡¨
    lines.extend([
        '## ğŸ“‹ å®Œæ•´åˆ—è¡¨',
        '',
        '| # | é¡¹ç›® | è¯­è¨€ | Star | ä»Šæ—¥ | å˜åŒ– | è¯„åˆ† |',
        '|---|------|------|------|------|------|------|',
    ])

    for i, analysis in enumerate(sorted_analyses, 1):
        repo = analysis.repo
        change = change_map.get(repo.name)
        change_str = format_rank_change(change) if change else '-'
        lang = repo.language or 'æœªçŸ¥'
        lines.append(f'| {i} | [{repo.name}]({repo.url}) | {lang} | {format_stars(repo.stars)} | +{repo.stars_today} | {change_str} | {analysis.score}/10 |')

    lines.extend([
        '',
        '---',
        '',
        f'ğŸ“… æ›´æ–°æ—¶é—´: {date.strftime("%Y-%m-%d %H:%M:%S")}',
        '',
        '> æœ¬æŠ¥å‘Šç”± [GitHub Trending Daily](https://github.com) è‡ªåŠ¨ç”Ÿæˆ',
    ])

    return '\n'.join(line for line in lines if line is not None)


if __name__ == '__main__':
    sys.exit(main())
